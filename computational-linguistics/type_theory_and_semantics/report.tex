%++++++++++++++++++++++++++++++++++++++++
\documentclass[letterpaper,12pt]{article}
\usepackage{tabularx} % extra features for tabular environment
\usepackage{amsmath}  % improve math presentation
\usepackage{graphicx} % takes care of graphic including machinery
\usepackage{stmaryrd} % for double brackets
%\usepackage[margin=1in,letterpaper]{geometry} % decreases margins
\usepackage{cite} % takes care of citations
\usepackage[final]{hyperref} % adds hyper links inside the generated pdf file
\hypersetup{
	colorlinks=true,       % false: boxed links; true: colored links
	linkcolor=blue,        % color of internal links
	citecolor=blue,        % color of links to bibliography
	filecolor=magenta,     % color of file links
	urlcolor=blue         
}
%++++++++++++++++++++++++++++++++++++++++


\begin{document}

\title{Progress Report - Independent Study}
\author{Atreyee Ghosal}
\date{1st October 2018}
\maketitle

\section{Background}

This report is a summary of the readings, discussion and work done in the Formal Logic and Semantics independent study up to this date.

Some important terms used here are:

\begin{itemize}
\item[Denotation]
The "surface" meaning of a linguistic element, what the element maps to in concept-space.
\end{itemize}

\section{Montague Semantics}

\begin{quote}
	There is in my opinion no important theoretical difference between natural languages and the artificial languages of logicians; indeed I consider it possible to comprehend the syntax and semantics of both kinds of languages with a single natural and mathematically precise theory. \\
\textit{- Richard Montague}
\end{quote}

\subsection{Frege's Principle of Compositionality}

This interpretation is a necessary constraint on both the syntactic and semantic algebras of a language.

The Principle of Compositionality:\\
The meaning of a complex expression is a function of the meanings of its parts and of the way they are syntactically combined.

It is to be noted that "syntactically combined" need not refer directly to the surface-level syntax of a language; it can be an intermediate logical/semantic representation language that stands in between the surface structure of an utterance and its meaning.

Example: phrase structure trees- the individual nodes and the way they are combined in the graph gives us the meaning of a sentence. Also, on the same principle: dependency trees- the nodes are objects and their arc labels syntactically combine them.

\subsection{The Syntactic Algebra}

The syntactic algebra contains elements (expressions) and operations which apply to tuples of expressions to yield other expressions; the language, in the simplest case, is the set of all expressions which can be formed by starting from some basic expressions (the generators of the algebra) and applying operations in all possible ways.

In practice, of course, there are syntactic and semantic constraints on which operators can be applied to which elements. See: selectional restrictions.

\subparagraph{A Question}
Are the words "algebra", "logic system", "calculus" etc used interchangably here? One of these words would be more directly understandable for the modern reader.

\subsection{The Semantic Algebra}

The semantic algebra contains denotations, and operations that apply to tuples of denotations to yield other denotations.

\subsection{What is Meaning/Denotation?}

\subsubsection{According To Montague}

The meaning, or denotation, of a sentence is the function from possible worlds/moments of time, to truth values. As in: \\
\\
\textit{Denotation Function : \{ States Of A Given World \} $\rightarrow$ \{ Boolean Truth Value \} }

\subsubsection{Another Interpretation: Meaning as A Change In State}

\begin{equation}
x := e  ::  \lambda S . S [ x \mapsto \llbracket e \rrbracket ]
\end{equation}
 Where state is a function of \textit{s}? 

\section{Basic Categorial Grammar}

The fundamental notion of basic categorial grammar is that linguistic signs can be complete or not complete. Under that perspective, grammatical composition can be described as the process of completing incomplete linguistic signs.

\subsection{Syntactic Categories}

Syntactic categories are of two types:

\begin{itemize}
\item[Complete]
Examples in our fragment: np, s.
\item[Incomplete]
Examples in our fragment: (np$\backslash$s)/np
\end{itemize}

\subsection{Semantic Types}

The syntactic category of a linguistic sign specifies the type of semantic denotation the sign has. This is expressed through category-to-type correspondence:

\subsubsection{Category to Type Correspondence}

A mapping from a set of categories to a set of types.

\begin{equation}
\begin{split}
\tau ( e ) = e \rightarrow m \\
e \in Categories \\
m \in Types \\
\end{split}
\end{equation}

A formal definition:

\subparagraph{Category To Type Correspondence}
Let $\tau$ be a function from a set of Categories to a set of Types. $\tau$ is a correspondence function iff: 
\begin{equation}
\tau ( \alpha \backslash \beta ) = \tau ( \beta \backslash \alpha ) = \langle \tau ( \alpha ), \tau ( \beta ) \rangle
\end{equation}

\subsubsection{Syntactic Categories: Why?}

A tentative answer to the above question based on my reading:

\begin{itemize}
\item
Syntactic categories offer a way to interpret positional arguments. For example: verb arguments in English are positional.
\item
Syntactic categories concern themselves with syntactic phenomena, which often have no effect on the deeper meaning of a sentence. Therefore, there can be a many-to-one mapping from categories to semantic types. For example: \\
"I picked a lock." \\
"A lock was picked by me." \\
Both the above sentences have the same meaning and same categories for the noun phrases "I" and "a lock", but different categories for the verbs as the role of the first/second noun phrases with relation to the verb are different.
\end{itemize}

\subsubsection{Semantic Types: Why?}

Categories denote a set of expressions, whereas Types denote a set of meanings.
\\
\fbox{Note: Is "denote" the correct term to use here?}
\\
Semantic types are useful because:

\begin{itemize}
\item
The semantic type corresponding to the category of a linguistic object restricts the possible denotations of the linguistic object. Therefore, a linguistic object in, say, category \textbf{A} can only denote objects of type \textbf{B}, where A \emph{corresponds to} B, or $\tau ( A ) = B$. For the definition of $\tau$, see category to type correspondence above.
\end{itemize}

\subsection{Defining Logic, Feature by Linguistic Feature}

The method used here is that- linguistic features (via "fragments" of English) are considered, and then a syntactic grammar is constructed to account for that feature, to which a semantic operation is mapped. However, basic categories cannot vary according to the fragment- thus, for example, the category of "Alice" in "Alice ate an ice-cream" would need to be the same as the category of "Alice" in "Alice and some people were walking." \\
Two examples of the above method are:
 
\subsubsection{Combinators and Co-Ordination}

Statement of our rule, which is prompted by linguistic observation: in English,
when two objects are compounded by the conjunction "and", the conjunction
"and" takes two arguments of the same category, and the resulting compounded
object also belongs to the categories of each of the arguments.

\begin{equation}
  \frac {X \Rightarrow A \hspace{40pt} Y \Rightarrow A}
  {X, and, Y \Rightarrow A}
\end{equation}

Where $\Rightarrow$ denotes \emph{belongs to the category of}

\paragraph{Semantic Operation:} The polymorphic co-ordination function
(syntactically) corresponds to a polymorphic set intersection function
(semantically).\\

\begin{equation}
  \frac {X \Rightarrow N : A \hspace{40pt} Y \Rightarrow N : A} 
  {X, and, Y \Rightarrow M \bigcap N : A}
\end{equation}

Here, $\Rightarrow$ means that X \emph{denotes} object M in semantic space. 

\subsubsection{Quantifiers and Co-Ordination}

\paragraph{Lifting Rule} Lifts a name to the category of a generalized
quantifier. $B/(A \backslash B)$ is the category of a quantifier.

\begin{equation}
  \frac {X \Rightarrow M : A}
  {X \Rightarrow \lambda x . xM : B/(A \backslash B)}
  L.R
\end{equation}

With the quantifier able to be placed to the left or to the right of x.

\subparagraph{Note:} what has the lambda function in the denominator got to do
with anything? Why are we using a lambda function to \emph{lift} a
type/category/catetype?


\section{Parse Trees as Proofs}

An useful part of in-meeting discussion! The concept of parse trees as proofs, and the basic elements of the parse tree as the premises! (Also helped me understand the programs-as-proofs way of thinking.)

And helped me understand the bit about a syntax tree as a deduction system.

Proofs, or derivations, are written in \emph{succedent} format, where \textbf{lexical entries} are the premises/axioms and appear at the leaves of the proof tree. 

\subsection{Structural Ambiguity as Multiple Proofs}

Structural or syntactic ambiguity- i.e: when a sentence has more than one possible syntax tree, each corresponding to a different end "meaning" of the sentence- can be thought of as multiple proofs on the same set of axioms. Take, for example, the sentence \\
\textbf{He saw Ram with binoculars.}

\begin{equation}
\cfrac
{	\cfrac {he} {np} 
 	\cfrac 
    {	\cfrac {saw} {np/s \backslash np} 
     	\cfrac
	    {	\cfrac {ram} {np \backslash pp}
	        \cfrac 
	    	{	\cfrac {with} {prep \backslash np}
	    	 	\cfrac {binoculars} {np}
	    	} 
	    	{pp}
	    }
	    {np}
	}
	{np/s}
} 
{s}
\end{equation}

Another interpretation can be (note: to denote attachment, the prepositional phrase "with binoculars" has been shifted to attach to the verb. This would be handled differently in a proper phrase structure grammar, which BCG seems to attempt to imitate, but I do not know what the BCG solution to attachment/shifting issues is):

\begin{equation}
\cfrac
{	\cfrac {he} {np} 
 	\cfrac 
    {	\cfrac {saw} {np/s \backslash np \backslash pp}
    	\cfrac 
	    {	\cfrac {with} {prep \backslash np}
	    	\cfrac {binoculars} {np}
	    } 
		{pp}
	}
	{np/s \backslash np} 
    \cfrac
	{	\cfrac {ram} {np}
	}
	{np}
} 
{s}
\end{equation}

Fact: this type of structural ambiguity is known as the \textbf{Prepositional Phrase Attachment Problem}
\end{document}
