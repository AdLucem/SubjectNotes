#+TITLE: An Unification-Based Approach To Compositionality
#+AUTHOR: C.A.L



Representation of a sentence will not be in a *lexicon*, while the representation of a word will.

We have to /derive/ the meaning of a sentence from the information present in the sentence.

Eg: "Ram_[person_named_ram] eats_[verb_meaning_consume] mangoes[noun_mangoes]."

How do we do that?

* A Basic PSG is Not Enough

Take a basic Phrase Structure Grammar. It overgenerates- generates ungrammatical sentences. Therefore, the grammar is not sufficient, and we have to add more constraints and conditions.

Eg: 

S --> NP VP
VP --> V NP
NP  --> Det N
Det --> a | the | these
N --> cake | cakes | boy | boys
V --> eat | eats

The above grammar will generate: "These boy eat a cakes."

Modifications to this grammar:

Add ~number agreement~ constraints to the rule =NP --> Det N=.

Add ~number agreement~ indicating that, in =S --> NP VP=, the ~head noun~ of the ~(subject) NP~ will agree in number with the ~head verb~ of the ~(predicate) VP~ 

But, at this point, we are going beyond what a simple Context Free Grammar can define. Therefore- we study a model that allows compositionality with constraints.

* Feature Structure

A feature structure is a list of features and values. We choose features that will help us derive semantic representations in the long run.

** Feature Structures As Types

Each feature structure, by itself, is labelled by a *type*. Each type has its own feature set- the type defines the feature set, and the feature set defines the type.

(We can see the reification of this in the feature structures explained later.)

And what do types help us do? Types help us hierarchize the feature structures, because we can form *type hierarchies* - with types lower on the hierarchy (more specific types) inheriting features of the more general types.

Think of this as something like types in a programming language.
Say, =number= is a head type. We can specify subtypes of =number= as =int=, =float=, etc..

The programming language analogy is just a rough analogy though.

** Types Within Types Within Types: Complex FS

Values within feature structures are themselves typed. Additionally, feature structures can have complex values- as in, a feature within a feature structure can have a value that is itself a feature structure. 

** Feature Structures As Directed Graphs

For convenience, we can represent a feature structure as a directed graph. This allows us to turn the problem of unification of features into a graph matching problem.

*** Unification Failure, Though

Of course, if arcs in the two digraphs don't match, then unification fails. 

Eg:

Digraph 1:  Root --[CAT]--> NP
                 --[NUM]--> SG

Digraph 2: Root --[CAT]--> NP
                --[NUM]--> PL

The unification of the two will fail because of the [NUM] arc.

* Some Feature Structure Descriptions

# According to what?

** Proper Noun

/prop-n-lxm/
---------------------------------
PHON --> /phon/

FORM --> /wordform/

SYN --> /syn-obj/
        -------------------------
        CAT --> /noun/
        VAL 

SEM --> /sem-obj/ 
       --------------------------
       INDEX
       LTOP
       FRAME --> /entity-fr/
                 ----------------
                 ENTITY
                 NAME
---------------------------------
       
** Verb

Here we take a frame for a transitive verb.

/trans-v-lxm/
----------------------------------------------------------------
PHON

FORM

SYN --> /syn-obj/
        --------------------------------------------------------
        CAT --> /verb/ 
        VAL --> <NP1, NP2> {Values of the syntactic arguments taken}
        --------------------------------------------------------

SEM --> /sem-obj/
        --------------------------------------------------------
        INDEX
        LTOP
        FRAME --> /event-fr/ {verbs represent events}
                  ----------------------------------------------
                  LABEL
                  SITUATION
                  AGENT {Defines the /types/ - i.e: the constraints put on- agent and theme taken by the verb. This helps us solve the problem of selectional restrictions.}
                  THEME {same as AGENT}
                  ----------------------------------------------
----------------------------------------------------------------
** /sem-obj/

/sem-obj/
----------------------------------------------------------------
INDEX  {The variable- used in logical rep. - assigned to an entity/situation/whatever}
LTOP {The label of a top frame in a composite expression}
FRAME --> /event-fr/ {verbs represent events. Refer to FrameNet to understand what this one is composed of.}
          ------------------------------------------------------
                  LABEL
                  SITUATION
                  AGENT {Defines the /types/ - i.e: the constraints put on- agent and theme taken by the verb. This helps us solve the problem of selectional restrictions.}
                  THEME {same as AGENT}
          ------------------------------------------------------
----------------------------------------------------------------

* LTOP Type, And The Importance Of Giving Head


It is the head of a sentence that relates to the head of the other sentences.

Also, the head and the information of its children that the head contains are being percolated down the feature graph. We capture this value using =LTOP= - the label of the top level frame in a combinatorial expression.
* Features As Types As Constraints

** Head Feature of a VP
* Constructing Semantic Structure of Sentences

We try to automate the process of assigning semantic representations of human languages?

The assumption here, is that we can use compopsitionality to derive the meaning of a sentence. I.e: we can use the meaning of the chunk to get the meaning of the bigger part (sentence).

However, we know that compositionality fails in a lot of cases. Eg: MWEs, idiomatic expressions.


** Unification as a well-formedness constraint-checking operation

# ???

# Wait how will this help the lack of compositionality?

Eg: "Ravi dORega."

(1) Take FSD of "dORa" (run)

Note: in this method, we have to define *all* the constraints. This harkens back to the problem I put up. But we can solve it by defining constraints on *types*, instead of individual verbs.

From this we can go to:

(2) FSD of inflected "dORega"

Referring to presentation, we can see that its FSD has two daughters.

We can see that the type of "dORega" is /fut-word/, as in, it is a *word*, not a lexeme (reminder: a lexeme is a 'headword').

The semantic structure has two matrices for the FRAME feature:

/some-fr/: says nothing but /there exists an event/ of this kind (run)
--> LBL
--> BV (Bound Variable): i.e: what does the verb have scope over
--> RSTR
# Alok: why are we taking an event as a variable anyway?
# Reason: we need to decompose events to refer to subevents, and we cannot decompose predicates
# I cannot record the full answer to the doubt
# TODO: expand this with notes from CSWFP
/fut-fr/: says that this event is in /future/ form

^^ This is based on *Event as a variable* (remember the E marker in verbnet?)
 It also has DTRS (DAUGHTERS) feature, which tells us from which *lexeme* this word has come from. Therefore, we can see the inflected word as a combination of the *lexemes* that form it.

# ENGLISH RESOURCE GRAMMAR- TAKE A LOOK AT IT
# ^ how to machine-learn grammar from the corpus??? once we have a suitably-sized manually-annotated corpus? ERG did it- how?

*** Composition of "ram" and "dORega"

/ref slide/

Type of the full sentence:

/sub-pred-constr/

<-- /word/
<-- /word/

** Why are types so important anyway?

*Types help in compatibility checks* - i.e: we can check with things like "this type does not go with that type"

Eg: in the /subject-predicate-construct/ type we can see that:

(1) It has a valence of /null/
(2) Semantics of it is a combination of semantics of /some-fr/, /fut-fr/, /run-fr/, /entity-fr/

So when the unification of the types in a sentence is successful, we get the semantics of the full sentence/phrase.

THIS BE COMPOSITIONALITY, BITCHES!

Note: order of compositionality does not matter.

